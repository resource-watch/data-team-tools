{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target directory of logged API json files, will create new one if it does not exist\n",
    "data_dir = 'rw_api_archive'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a copy of RW dataset, layer, and widget endpoints. Note 'env' and 'application' params in URL string\n",
    "api_list = ['dataset','layer','widget']\n",
    "MAX_ITER = 20\n",
    "\n",
    "## Handle pagination\n",
    "def follow_pagination(link_obj):\n",
    "\tif not isinstance(link_obj, dict):\n",
    "\t\treturn (-1, '')\n",
    "\tif link_obj['self'] == link_obj['last']:\n",
    "\t\treturn (0, '')\n",
    "\treturn (1, link_obj['next'])\n",
    "\n",
    "## Loop through each endpoint\n",
    "for endpoint in api_list:\n",
    "\n",
    "    data = []\n",
    "    current_url = f'http://api.resourcewatch.org/v1/{endpoint}?page[size]=1000&env=production&application=rw'\n",
    "\n",
    "    for i in range(MAX_ITER):\n",
    "        with requests.get(current_url) as r:\n",
    "            print(current_url)\n",
    "            if r.ok:\n",
    "                ds = json.loads(r.content)\n",
    "            else:\n",
    "                raise ValueError(f'API request failed: {current_url}')\n",
    "        assert 'data' in ds\n",
    "        assert 'links' in ds\n",
    "\n",
    "        # Add each page of results together\n",
    "        data.extend(ds['data'])\n",
    "\n",
    "        # Stop if there are no more results\n",
    "        code, link = follow_pagination(ds['links'])\n",
    "        if code == 1:\n",
    "            current_url = link\n",
    "        elif code == 0:\n",
    "            print(\"Last page reached\")\n",
    "            break\n",
    "        elif code == -1:\n",
    "            raise TypeError('links object in API response malformed')\n",
    "        else:\n",
    "            raise ValueError(f'pagination response malformed or not understood')\n",
    "        \n",
    "        \n",
    "    d8 = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "    with open(f'{data_dir}/{endpoint}_{d8}.json', 'w') as fp:\n",
    "            json.dump(data, fp)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select filename of most recent matching json files in target directory and load as json\n",
    "recent_dataset_dl = max(glob.iglob(f'{data_dir}/datas*.json'), key=os.path.getctime)\n",
    "recent_layer_dl = max(glob.iglob(f'{data_dir}/layer*.json'), key=os.path.getctime)\n",
    "recent_widget_dl = max(glob.iglob(f'{data_dir}/widge*.json'), key=os.path.getctime)\n",
    "\n",
    "with open(recent_dataset_dl) as json_file:\n",
    "    rw_dataset_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_layer_dl) as json_file:\n",
    "    rw_layer_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_widget_dl) as json_file:\n",
    "    rw_widget_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set substring, will search for string across all json objects\n",
    "subs = 'ene_028_access_clean_cooking' #<-- SET SUBSTRING HERE\n",
    "layers_using = [x for x in rw_layer_data if str(x).count(subs) != 0] \n",
    "widgets_using = [x for x in rw_widget_data if str(x).count(subs) != 0] \n",
    "datasets_using = [x for x in rw_dataset_data if str(x).count(subs) != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List ids of all matching objects\n",
    "litems = [datasets_using, layers_using, widgets_using]\n",
    "print(subs)\n",
    "for i, x in enumerate(['datasets', 'layers', 'widgets']):\n",
    "    print(x)\n",
    "    for j in litems[i]:\n",
    "        print('https://resourcewatch.org/admin/data/{}/{}/edit'.format(x, j['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
