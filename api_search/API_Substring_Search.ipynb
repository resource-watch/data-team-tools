{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target directory\n",
    "# of logged API json files, will create new one if it does not exist\n",
    "data_dir = 'rw_api_archive'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a copy of RW dataset, layer, and widget endpoints. \n",
    "# Note 'env' and 'application' params in URL string\n",
    "api_list = ['dataset','layer','widget']\n",
    "MAX_ITER = 20\n",
    "\n",
    "## Handle pagination\n",
    "def follow_pagination(link_obj):\n",
    "\tif not isinstance(link_obj, dict):\n",
    "\t\treturn (-1, '')\n",
    "\tif link_obj['self'] == link_obj['last']:\n",
    "\t\treturn (0, '')\n",
    "\treturn (1, link_obj['next'])\n",
    "\n",
    "## Loop through each endpoint\n",
    "for endpoint in api_list:\n",
    "\n",
    "    data = []\n",
    "    current_url = f'http://api.resourcewatch.org/v1/{endpoint}?page[size]=1000&env=production&application=rw'\n",
    "\n",
    "    for i in range(MAX_ITER):\n",
    "        with requests.get(current_url) as r:\n",
    "            print(current_url)\n",
    "            if r.ok:\n",
    "                ds = json.loads(r.content)\n",
    "            else:\n",
    "                raise ValueError(f'API request failed: {current_url}')\n",
    "        assert 'data' in ds\n",
    "        assert 'links' in ds\n",
    "\n",
    "        # Add each page of results together\n",
    "        data.extend(ds['data'])\n",
    "\n",
    "        # Stop if there are no more results\n",
    "        code, link = follow_pagination(ds['links'])\n",
    "        if code == 1:\n",
    "            current_url = link\n",
    "        elif code == 0:\n",
    "            print(\"Last page reached\")\n",
    "            break\n",
    "        elif code == -1:\n",
    "            raise TypeError('links object in API response malformed')\n",
    "        else:\n",
    "            raise ValueError(f'pagination response malformed or not understood')\n",
    "        \n",
    "        \n",
    "    d8 = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "    with open(f'{data_dir}/{endpoint}_{d8}.json', 'w') as fp:\n",
    "            json.dump(data, fp)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select filename of most recent matching json files in target directory and load as json\n",
    "recent_dataset_dl = max(glob.iglob(f'{data_dir}/datas*.json'), key=os.path.getctime)\n",
    "recent_layer_dl = max(glob.iglob(f'{data_dir}/layer*.json'), key=os.path.getctime)\n",
    "recent_widget_dl = max(glob.iglob(f'{data_dir}/widge*.json'), key=os.path.getctime)\n",
    "\n",
    "with open(recent_dataset_dl) as json_file:\n",
    "    rw_dataset_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_layer_dl) as json_file:\n",
    "    rw_layer_data = json.load(json_file)\n",
    "    \n",
    "with open(recent_widget_dl) as json_file:\n",
    "    rw_widget_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set substring, will search for string across all json objects\n",
    "subs = 'globalfishingwatch' #<-- SET SUBSTRING HERE\n",
    "layers_using = [x for x in rw_layer_data if str(x).count(subs) != 0] \n",
    "widgets_using = [x for x in rw_widget_data if str(x).count(subs) != 0] \n",
    "datasets_using = [x for x in rw_dataset_data if str(x).count(subs) != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List edit urls of all matching objects\n",
    "litems = [datasets_using, layers_using, widgets_using]\n",
    "print(subs)\n",
    "for i, x in enumerate(['datasets', 'layers', 'widgets']):\n",
    "    print(x)\n",
    "    for j in litems[i]:\n",
    "        print('https://resourcewatch.org/admin/data/{}/{}/edit'.format(x, j['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://api.resourcewatch.org/v1/dataset/6ccfb266-20cd-4838-82b0-5309987a62f0',\n",
       " 'https://api.resourcewatch.org/v1/dataset/11f16cb9-def0-4bd5-a60e-50c542b837e3',\n",
       " 'https://api.resourcewatch.org/v1/layer/30c90ee1-ce3f-4a30-afdb-5929ae91a684',\n",
       " 'https://api.resourcewatch.org/v1/layer/1f11414a-266c-4ca0-83ae-6f07ab7e85df',\n",
       " 'https://api.resourcewatch.org/v1/layer/02066566-f854-46b7-816a-6810a715e3c0',\n",
       " 'https://api.resourcewatch.org/v1/layer/23f9c85a-c2bf-4589-a6b9-5e8e434e5474',\n",
       " 'https://api.resourcewatch.org/v1/layer/359dc32b-8724-456e-bbe7-bfbc19b4b789',\n",
       " 'https://api.resourcewatch.org/v1/layer/516c8b3f-47e3-486f-a6c6-7c31ff226d98',\n",
       " 'https://api.resourcewatch.org/v1/layer/87c66011-0859-4042-9b71-94d2376f7b35',\n",
       " 'https://api.resourcewatch.org/v1/layer/68ee1a1d-770d-4efb-be4e-eaace0d97bb0',\n",
       " 'https://api.resourcewatch.org/v1/layer/1ecc70ac-bf72-4d2a-9a84-196cf86be0d5',\n",
       " 'https://api.resourcewatch.org/v1/layer/3a9b0873-4abf-4ad8-8845-0201bd7b88ee',\n",
       " 'https://api.resourcewatch.org/v1/layer/a0358ad1-4f85-4b9f-bddb-9d50c25073d9',\n",
       " 'https://api.resourcewatch.org/v1/layer/84b4a366-3fbe-4d2c-b4af-3375d33533ac',\n",
       " 'https://api.resourcewatch.org/v1/layer/209aab6f-fde2-4812-aad3-0ec9dc53b1c0',\n",
       " 'https://api.resourcewatch.org/v1/layer/9996d3e5-c6d6-4f0c-957d-69b79359e327',\n",
       " 'https://api.resourcewatch.org/v1/layer/e85394f4-277b-4694-b7d6-fcd522cb90c0',\n",
       " 'https://api.resourcewatch.org/v1/layer/9255ac70-79e2-408f-8381-890dae9cbd54',\n",
       " 'https://api.resourcewatch.org/v1/layer/43b65de8-889f-4657-8538-4a5384ddee55',\n",
       " 'https://api.resourcewatch.org/v1/layer/470daff1-e02a-4d9a-a2cd-e77b6e81fc40',\n",
       " 'https://api.resourcewatch.org/v1/layer/aa59e1ba-1daa-426b-83f5-ecdf0982b015',\n",
       " 'https://api.resourcewatch.org/v1/layer/cc94f3eb-62d5-4b6e-867e-9a8b04c72908',\n",
       " 'https://api.resourcewatch.org/v1/layer/759ec87f-2972-4508-8049-5e718f1d73e0',\n",
       " 'https://api.resourcewatch.org/v1/layer/7b2a03d7-bbc7-4ba6-a120-fe110ae35759']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of api endpoints of all matching objects\n",
    "litems = [datasets_using, layers_using, widgets_using]\n",
    "results = []\n",
    "for i, x in enumerate(['dataset', 'layer', 'widget']):\n",
    "    for j in litems[i]:\n",
    "        results.append('https://api.resourcewatch.org/v1/{}/{}'.format(x, j['id']))\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
